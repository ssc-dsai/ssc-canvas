"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.getModelConfig = exports.formatArtifactContentWithTemplate = exports.formatArtifactContent = exports.ensureStoreInConfig = exports.formatReflections = void 0;
exports.getFormattedReflections = getFormattedReflections;
exports.optionallyGetSystemPromptFromConfig = optionallyGetSystemPromptFromConfig;
exports.isUsingO1MiniModel = isUsingO1MiniModel;
exports.getModelFromConfig = getModelFromConfig;
exports.convertPDFToText = convertPDFToText;
exports.createContextDocumentMessagesAnthropic = createContextDocumentMessagesAnthropic;
exports.createContextDocumentMessagesGemini = createContextDocumentMessagesGemini;
exports.createContextDocumentMessagesOpenAI = createContextDocumentMessagesOpenAI;
exports.createContextDocumentMessages = createContextDocumentMessages;
exports.formatMessages = formatMessages;
exports.createAIMessageFromWebResults = createAIMessageFromWebResults;
exports.getStringFromContent = getStringFromContent;
const uuid_1 = require("uuid");
const artifacts_1 = require("@opencanvas/shared/utils/artifacts");
const universal_1 = require("langchain/chat_models/universal");
const pdf_parse_1 = __importDefault(require("pdf-parse"));
const messages_1 = require("@langchain/core/messages");
const constants_1 = require("@opencanvas/shared/constants");
const models_1 = require("@opencanvas/shared/models");
const supabase_js_1 = require("@supabase/supabase-js");
const formatReflections = (reflections, extra) => {
    if (extra?.onlyStyle && extra?.onlyContent) {
        throw new Error("Cannot specify both `onlyStyle` and `onlyContent` as true.");
    }
    let styleRulesArr = reflections.styleRules;
    let styleRulesStr = "No style guidelines found.";
    if (!Array.isArray(styleRulesArr)) {
        try {
            styleRulesArr = JSON.parse(styleRulesArr);
            styleRulesStr = styleRulesArr.join("\n- ");
        }
        catch (_) {
            console.error("FAILED TO PARSE STYLE RULES. \n\ntypeof:", typeof styleRulesArr, "\n\nstyleRules:", styleRulesArr);
        }
    }
    let contentRulesArr = reflections.content;
    let contentRulesStr = "No memories/facts found.";
    if (!Array.isArray(contentRulesArr)) {
        try {
            contentRulesArr = JSON.parse(contentRulesArr);
            contentRulesStr = contentRulesArr.join("\n- ");
        }
        catch (_) {
            console.error("FAILED TO PARSE CONTENT RULES. \n\ntypeof:", typeof contentRulesArr, "\ncontentRules:", contentRulesArr);
        }
    }
    const styleString = `The following is a list of style guidelines previously generated by you:
<style-guidelines>
- ${styleRulesStr}
</style-guidelines>`;
    const contentString = `The following is a list of memories/facts you previously generated about the user:
<user-facts>
- ${contentRulesStr}
</user-facts>`;
    if (extra?.onlyStyle) {
        return styleString;
    }
    if (extra?.onlyContent) {
        return contentString;
    }
    return styleString + "\n\n" + contentString;
};
exports.formatReflections = formatReflections;
const ensureStoreInConfig = (config) => {
    if (!config.store) {
        throw new Error("`store` not found in config");
    }
    return config.store;
};
exports.ensureStoreInConfig = ensureStoreInConfig;
async function getFormattedReflections(config) {
    if (!config.store) {
        return "No reflections found.";
    }
    const store = (0, exports.ensureStoreInConfig)(config);
    const assistantId = config.configurable?.assistant_id;
    if (!assistantId) {
        throw new Error("`assistant_id` not found in configurable");
    }
    const memoryNamespace = ["memories", assistantId];
    const memoryKey = "reflection";
    const memories = await store.get(memoryNamespace, memoryKey);
    const memoriesAsString = memories?.value
        ? (0, exports.formatReflections)(memories.value)
        : "No reflections found.";
    return memoriesAsString;
}
const formatArtifactContent = (content, shortenContent) => {
    let artifactContent;
    if ((0, artifacts_1.isArtifactCodeContent)(content)) {
        artifactContent = shortenContent
            ? content.code?.slice(0, 500)
            : content.code;
    }
    else {
        artifactContent = shortenContent
            ? content.fullMarkdown?.slice(0, 500)
            : content.fullMarkdown;
    }
    return `Title: ${content.title}\nArtifact type: ${content.type}\nContent: ${artifactContent}`;
};
exports.formatArtifactContent = formatArtifactContent;
const formatArtifactContentWithTemplate = (template, content, shortenContent) => {
    return template.replace("{artifact}", (0, exports.formatArtifactContent)(content, shortenContent));
};
exports.formatArtifactContentWithTemplate = formatArtifactContentWithTemplate;
const getModelConfig = (config, extra) => {
    const customModelName = config.configurable?.customModelName;
    if (!customModelName)
        throw new Error("Model name is missing in config.");
    const modelConfig = config.configurable?.modelConfig;
    if (customModelName.startsWith("azure/")) {
        let actualModelName = customModelName.replace("azure/", "");
        if (extra?.isToolCalling && actualModelName.includes("o1")) {
            // Fallback to 4o model for tool calling since o1 does not support tools.
            actualModelName = "gpt-4o";
        }
        return {
            modelName: actualModelName,
            modelProvider: "azure_openai",
            azureConfig: {
                azureOpenAIApiKey: process.env._AZURE_OPENAI_API_KEY || "",
                azureOpenAIApiInstanceName: process.env._AZURE_OPENAI_API_INSTANCE_NAME || "",
                azureOpenAIApiDeploymentName: process.env._AZURE_OPENAI_API_DEPLOYMENT_NAME || "",
                azureOpenAIApiVersion: process.env._AZURE_OPENAI_API_VERSION || "2024-08-01-preview",
                azureOpenAIBasePath: process.env._AZURE_OPENAI_API_BASE_PATH,
            },
        };
    }
    const providerConfig = {
        modelName: customModelName,
        modelConfig,
    };
    if (customModelName.includes("gpt-") ||
        customModelName.includes("o1") ||
        customModelName.includes("o3")) {
        let actualModelName = providerConfig.modelName;
        if (extra?.isToolCalling && actualModelName.includes("o1")) {
            // Fallback to 4o model for tool calling since o1 does not support tools.
            actualModelName = "gpt-4o";
        }
        return {
            ...providerConfig,
            modelName: actualModelName,
            modelProvider: "openai",
            apiKey: process.env.OPENAI_API_KEY,
        };
    }
    if (customModelName.includes("claude-")) {
        return {
            ...providerConfig,
            modelProvider: "anthropic",
            apiKey: process.env.ANTHROPIC_API_KEY,
        };
    }
    if (customModelName.includes("fireworks/")) {
        let actualModelName = providerConfig.modelName;
        if (extra?.isToolCalling &&
            actualModelName !== "accounts/fireworks/models/llama-v3p3-70b-instruct") {
            actualModelName = "accounts/fireworks/models/llama-v3p3-70b-instruct";
        }
        return {
            ...providerConfig,
            modelName: actualModelName,
            modelProvider: "fireworks",
            apiKey: process.env.FIREWORKS_API_KEY,
        };
    }
    if (customModelName.startsWith("groq/")) {
        const actualModelName = customModelName.replace("groq/", "");
        return {
            modelName: actualModelName,
            modelProvider: "groq",
            apiKey: process.env.GROQ_API_KEY,
        };
    }
    if (customModelName.includes("gemini-")) {
        let actualModelName = providerConfig.modelName;
        if (extra?.isToolCalling && actualModelName.includes("thinking")) {
            // Gemini thinking does not support tools.
            actualModelName = "gemini-2.0-flash-exp";
        }
        return {
            ...providerConfig,
            modelName: actualModelName,
            modelProvider: "google-genai",
            apiKey: process.env.GOOGLE_API_KEY,
        };
    }
    if (customModelName.includes("gemini-")) {
        let actualModelName = providerConfig.modelName;
        if (extra?.isToolCalling && actualModelName.includes("thinking")) {
            // Gemini thinking does not support tools.
            actualModelName = "gemini-2.0-flash-exp";
        }
        return {
            ...providerConfig,
            modelName: actualModelName,
            modelProvider: "google-genai",
            apiKey: process.env.GOOGLE_API_KEY,
        };
    }
    if (customModelName.startsWith("ollama-")) {
        return {
            modelName: customModelName.replace("ollama-", ""),
            modelProvider: "ollama",
            baseUrl: process.env.OLLAMA_API_URL || "http://host.docker.internal:11434",
        };
    }
    throw new Error("Unknown model provider");
};
exports.getModelConfig = getModelConfig;
function optionallyGetSystemPromptFromConfig(config) {
    return config.configurable?.systemPrompt;
}
async function getUserFromConfig(config) {
    if (!process.env.NEXT_PUBLIC_SUPABASE_URL ||
        !process.env.SUPABASE_SERVICE_ROLE) {
        return undefined;
    }
    const accessToken = config.configurable?.supabase_session?.access_token;
    if (!accessToken) {
        return undefined;
    }
    const supabase = (0, supabase_js_1.createClient)(process.env.NEXT_PUBLIC_SUPABASE_URL, process.env.SUPABASE_SERVICE_ROLE);
    const authRes = await supabase.auth.getUser(accessToken);
    return authRes.data.user || undefined;
}
function isUsingO1MiniModel(config) {
    const { modelName } = (0, exports.getModelConfig)(config);
    return modelName.includes("o1-mini");
}
async function getModelFromConfig(config, extra) {
    const { modelName, modelProvider, azureConfig, apiKey, baseUrl, modelConfig, } = (0, exports.getModelConfig)(config, {
        isToolCalling: extra?.isToolCalling,
    });
    const { temperature = 0.5, maxTokens } = {
        temperature: modelConfig?.temperatureRange.current,
        maxTokens: modelConfig?.maxTokens.current,
        ...extra,
    };
    const isLangChainUserModel = models_1.LANGCHAIN_USER_ONLY_MODELS.some((m) => m === modelName);
    if (isLangChainUserModel) {
        const user = await getUserFromConfig(config);
        if (!user) {
            throw new Error("Unauthorized. Can not use LangChain only models without a user.");
        }
        if (!user.email?.endsWith("@langchain.dev")) {
            throw new Error("Unauthorized. Can not use LangChain only models without a user with a @langchain.dev email.");
        }
    }
    const includeStandardParams = !models_1.TEMPERATURE_EXCLUDED_MODELS.some((m) => m === modelName);
    return await (0, universal_1.initChatModel)(modelName, {
        modelProvider,
        // Certain models (e.g., OpenAI o1) do not support passing the temperature param.
        ...(includeStandardParams
            ? { maxTokens, temperature }
            : {
                max_completion_tokens: maxTokens,
                // streaming: false,
                // disableStreaming: true,
            }),
        ...(baseUrl ? { baseUrl } : {}),
        ...(apiKey ? { apiKey } : {}),
        ...(azureConfig != null
            ? {
                azureOpenAIApiKey: azureConfig.azureOpenAIApiKey,
                azureOpenAIApiInstanceName: azureConfig.azureOpenAIApiInstanceName,
                azureOpenAIApiDeploymentName: azureConfig.azureOpenAIApiDeploymentName,
                azureOpenAIApiVersion: azureConfig.azureOpenAIApiVersion,
                azureOpenAIBasePath: azureConfig.azureOpenAIBasePath,
            }
            : {}),
    });
}
const cleanBase64 = (base64String) => {
    return base64String.replace(/^data:.*?;base64,/, "");
};
async function convertPDFToText(base64PDF) {
    try {
        // Clean the base64 input first
        const cleanedBase64 = cleanBase64(base64PDF);
        // Convert cleaned base64 to buffer
        const pdfBuffer = Buffer.from(cleanedBase64, "base64");
        // Parse PDF
        const data = await (0, pdf_parse_1.default)(pdfBuffer);
        // Get text content
        return data.text;
    }
    catch (error) {
        console.error("Error converting PDF to text:", error);
        throw error;
    }
}
async function createContextDocumentMessagesAnthropic(documents, options) {
    const messagesPromises = documents.map(async (doc) => {
        if (doc.type === "application/pdf" && options?.nativeSupport) {
            return {
                type: "document",
                source: {
                    type: "base64",
                    media_type: doc.type,
                    data: cleanBase64(doc.data),
                },
            };
        }
        let text = "";
        if (doc.type === "application/pdf" && !options?.nativeSupport) {
            text = await convertPDFToText(doc.data);
        }
        else if (doc.type.startsWith("text/")) {
            text = atob(cleanBase64(doc.data));
        }
        else if (doc.type === "text") {
            text = doc.data;
        }
        return {
            type: "text",
            text,
        };
    });
    return await Promise.all(messagesPromises);
}
function createContextDocumentMessagesGemini(documents) {
    return documents.map((doc) => {
        if (doc.type === "application/pdf") {
            return {
                type: doc.type,
                data: cleanBase64(doc.data),
            };
        }
        else if (doc.type.startsWith("text/")) {
            return {
                type: "text",
                text: atob(cleanBase64(doc.data)),
            };
        }
        else if (doc.type === "text") {
            return {
                type: "text",
                text: doc.data,
            };
        }
        throw new Error("Unsupported document type: " + doc.type);
    });
}
async function createContextDocumentMessagesOpenAI(documents) {
    const messagesPromises = documents.map(async (doc) => {
        let text = "";
        if (doc.type === "application/pdf") {
            text = await convertPDFToText(doc.data);
        }
        else if (doc.type.startsWith("text/")) {
            text = atob(cleanBase64(doc.data));
        }
        else if (doc.type === "text") {
            text = doc.data;
        }
        return {
            type: "text",
            text,
        };
    });
    return await Promise.all(messagesPromises);
}
async function getContextDocuments(config) {
    const store = config.store;
    const assistantId = config.configurable?.assistant_id;
    if (!store || !assistantId) {
        return [];
    }
    const result = await store.get(constants_1.CONTEXT_DOCUMENTS_NAMESPACE, assistantId);
    return result?.value?.documents || [];
}
async function createContextDocumentMessages(config, contextDocuments) {
    const { modelProvider, modelName } = (0, exports.getModelConfig)(config);
    const documents = contextDocuments || [];
    if (!documents.length && config) {
        const docs = await getContextDocuments(config);
        documents.push(...docs);
    }
    if (!documents.length) {
        return [];
    }
    let contextDocumentMessages = [];
    if (modelProvider === "openai") {
        contextDocumentMessages =
            await createContextDocumentMessagesOpenAI(documents);
    }
    else if (modelProvider === "anthropic") {
        const nativeSupport = modelName.includes("3-5-sonnet");
        contextDocumentMessages = await createContextDocumentMessagesAnthropic(documents, {
            nativeSupport,
        });
    }
    else if (modelProvider === "google-genai") {
        contextDocumentMessages = createContextDocumentMessagesGemini(documents);
    }
    if (!contextDocumentMessages.length)
        return [];
    let contextMessages = [];
    if (contextDocumentMessages?.length) {
        contextMessages = [
            {
                role: "user",
                content: [
                    {
                        type: "text",
                        text: "Use the file(s) and/or text below as context when generating your response.",
                    },
                    ...contextDocumentMessages,
                ],
            },
        ];
    }
    return contextMessages;
}
function formatMessages(messages) {
    return messages
        .map((msg, idx) => {
        const msgType = "_getType" in msg
            ? msg._getType()
            : "type" in msg
                ? msg?.type
                : "unknown";
        const messageContent = typeof msg.content === "string"
            ? msg.content
            : msg.content
                .flatMap((c) => ("text" in c ? c.text : []))
                .join("\n");
        return `<${msgType} index="${idx}">\n${messageContent}\n</${msgType}>`;
    })
        .join("\n");
}
function createAIMessageFromWebResults(webResults) {
    const webResultsStr = webResults
        .map((r, index) => `<search-result
      index="${index}"
      publishedDate="${r.metadata?.publishedDate || "Unknown"}"
      author="${r.metadata?.author || "Unknown"}"
    >
      [${r.metadata?.title || "Unknown title"}](${r.metadata?.url || "Unknown URL"})
      ${r.pageContent}
    </search-result>`)
        .join("\n\n");
    const content = `Here is some additional context I found from searching the web. This may be useful:\n\n${webResultsStr}`;
    return new messages_1.AIMessage({
        content,
        id: `web-search-results-${(0, uuid_1.v4)()}`,
        additional_kwargs: {
            [constants_1.OC_WEB_SEARCH_RESULTS_MESSAGE_KEY]: true,
            webSearchResults: webResults,
            webSearchStatus: "done",
        },
    });
}
function getStringFromContent(content) {
    if (typeof content === "string") {
        return content;
    }
    return content
        .flatMap((c) => ("text" in c ? c.text : []))
        .join("\n");
}
